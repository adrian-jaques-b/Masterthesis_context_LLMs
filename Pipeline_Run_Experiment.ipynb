{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3e8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022be46-3ee1-4e94-ba59-c6fd90fd303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "path = \"PREPARE_Datasets_Hatebase/\"\n",
    "file_path = path + \"FINAL_IMSyPP_EN_561_PREPROCESSED_no_restricted_videos_features_2ktoken_w_prompt_u_desc_audio_object_with_video_and_reply_metadata_no_missing.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "len(df)\n",
    "df_test = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22acfdad-942a-496a-b16a-bff1828a30c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_number = '1' #you can use 1,2,3 etc.. (defined in pipeline.py)\n",
    "\n",
    "pipeline = {\n",
    "    \"pipeline\": f\"pipeline_{pipeline_number}\"\n",
    "}\n",
    "\n",
    "# Save the variables to a JSON file\n",
    "with open('choose_pipeline.json', 'w') as f:\n",
    "    json.dump(pipeline, f)\n",
    "\n",
    "\n",
    "# Define the variables\n",
    "variables = {\n",
    "    \"GROQ_API_KEY\": \"<KEY>\",\n",
    "    \"OPENAI_API_KEY\": \"<KEY>\",\n",
    "    \"use_openai\": True,\n",
    "    \"model_name\": \"all-MiniLM-L6-v2.gguf2.f16.gguf\",\n",
    "    \"collection_name\": \"MA_GPT4\",\n",
    "    \"persist_directory\": \"./db_GPT4\",\n",
    "    \"chat_model\": \"gpt-3.5-turbo-0125\", #mixtral-8x7b-32768\", # Add your desired model\n",
    "    \"model\": \"gpt-3.5-turbo-0125\", # Add your desired model\n",
    "    \"output_path_experiments\": \"./experiments_outputs/\",\n",
    "    \"content_used\": \"EN_classify_reply_comment_title_definition_description_descriptionYT_transcript_audio_event_object\",  # Add this variable or adjust as needed\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Save the variables to a JSON file\n",
    "with open(f'variables{pipeline_number}.json', 'w') as f:\n",
    "    json.dump(variables, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3ed74-d69e-4fc5-8df9-583f96f52cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_used = variables[\"content_used\"]\n",
    "content_used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfab70-f9c0-4365-908e-10f41279f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_test#[155:]\n",
    "df_input.comment.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58095e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"{content_used}_classify_replies_561_GPT35T_Hatebase_1\"\n",
    "output_file = f\"./experiments_outputs/{file_name}.csv\"\n",
    "print(output_file)\n",
    "\n",
    "variables_logging = {\n",
    "    \"approach_name\":  file_name \n",
    "}\n",
    "\n",
    "# Save the variables to a JSON file\n",
    "with open(f'settings_logging.json', 'w') as f:\n",
    "    json.dump(variables_logging, f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756f024-8f1a-4650-abe3-6b90ce702eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pipeline as pipe\n",
    "os.environ.get(\"<KEY>\")\n",
    "\n",
    "# Example usage\n",
    "row_index = None #66#None #3  # Set to None to process all rows\n",
    "use_predefined = False#True  # Set to True to use predefined context and reply for the specific index\n",
    "#content_used = \"EN_reply_comment_title_transcript\" #\"title_transcript_comment_reply\"\n",
    "content_used = variables[\"content_used\"]\n",
    "language =\"EN\"\n",
    "\n",
    "\n",
    "# output_path_experiments = \"./experiments_outputs/\"\n",
    "# output_file = output_path_experiments + f'{content_used}_classify_replies_800_no_duplicates.csv'\n",
    "\n",
    "# predefined_comment = \"Was geht mit den Ãœ30 ab? ðŸ˜‚ Diese Probleme hÃ¤tte ich auch gerne, sich einfach angegriffen zu fÃ¼hlen\"\n",
    "# predefined_reply = \"ðŸ˜‚ machmal tut es weh\"\n",
    "\n",
    "\n",
    "''' You can choose between iterating through a whole dataset/dataframe or by only using one specific row by index. \n",
    "Also, if only one row is used a custom comment and reply text can be used since these are currently not defined in the dataset. \n",
    "(Therefore the iterating approach is currently not working)'''\n",
    "custom_entities = []\n",
    "\n",
    "#classes = [\"abusive\", \"non-abusive\", \"-uncertain or borderline\"]\n",
    "classes = [\"appropriate\", \"inappropriate\", \"offensive\", \"violent\"]\n",
    "response_df = pipe.main_pipeline(df_input, classes, content_used, custom_entities, language, index=row_index, use_wikipedia_directly=True, use_attention_score=False, use_spacy=True, use_propn=False, use_keywords=False, predefined_context=predefined_comment if use_predefined else None, predefined_reply=predefined_reply if use_predefined else None)\n",
    "\n",
    "response_df.to_csv(output_file, sep = ';', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
