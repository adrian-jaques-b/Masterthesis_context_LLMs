{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\aboeck/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-7-9 Python-3.10.14 torch-2.3.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video processing...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import json\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from moviepy.editor import VideoFileClip\n",
    "import time\n",
    "\n",
    "# Load YOLOv5 model\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "def extract_key_frames(video_path, num_key_frames=25):\n",
    "    print(f\"Extracting key frames from {video_path}\")\n",
    "    clip = VideoFileClip(video_path)\n",
    "    duration = clip.duration\n",
    "    frames = [clip.get_frame(t) for t in np.linspace(0, duration, num_key_frames)]\n",
    "    return frames\n",
    "\n",
    "def detect_objects_in_frames(frames):\n",
    "    detected_objects = []\n",
    "    for frame in frames:\n",
    "        print(\"Detecting objects in a frame...\")\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        results = yolo_model(img)\n",
    "        detected_objects.extend(results.pandas().xyxy[0]['name'].tolist())\n",
    "    return list(set(detected_objects))\n",
    "\n",
    "def process_video(video_info):\n",
    "    video_id, video_path = video_info\n",
    "    if os.path.exists(video_path):\n",
    "        key_frames = extract_key_frames(video_path)\n",
    "        detected_objects = detect_objects_in_frames(key_frames)\n",
    "        return video_id, detected_objects\n",
    "    else:\n",
    "        return video_id, []\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"FINAL_IMSyPP_EN_644_PREPROCESSED_no_restricted_videos_features_2ktoken_w_prompt_u_desc_audio.xlsx\")\n",
    "\n",
    "# For testing, limit the number of videos processed\n",
    "df = df[:2]\n",
    "\n",
    "df['detected_objects'] = \"\"\n",
    "\n",
    "video_directory = \"NEW_Hatebase_dataset_downloaded_videos\"\n",
    "video_info_list = [(row['video_id'], os.path.join(video_directory, f\"{row['video_id']}.mp4\")) for _, row in df.iterrows()]\n",
    "\n",
    "print(\"Starting video processing...\")\n",
    "start_time = time.time()\n",
    "\n",
    "with Pool(cpu_count()) as pool:\n",
    "    results = pool.map(process_video, video_info_list)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Video processing completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "detected_objects = {video_id: objects for video_id, objects in results}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    df.at[index, 'detected_objects'] = json.dumps(detected_objects[video_id])\n",
    "\n",
    "# Uncomment the line below to save the results to an Excel file\n",
    "# df.to_excel(\"FINAL_IMSyPP_EN_644_PREPROCESSED_no_restricted_videos_features_2ktoken_w_prompt_u_desc_audio_object_detection.xlsx\", index=False)\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
