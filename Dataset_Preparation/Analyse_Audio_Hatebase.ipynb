{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Load YAMNet model from TensorFlow Hub\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet = hub.load(yamnet_model_handle)\n",
    "\n",
    "# Fetch class names\n",
    "class_map_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/audioset/yamnet/yamnet_class_map.csv'\n",
    "response = requests.get(class_map_url)\n",
    "class_map_csv = response.text\n",
    "class_names = [line.split(',')[2].strip().replace('\"', '') for line in class_map_csv.splitlines()[1:]]\n",
    "\n",
    "def extract_audio_from_video(video_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio_path = video_path.replace('.mp4', '.wav')\n",
    "    video.audio.write_audiofile(audio_path, codec='pcm_s16le')\n",
    "    return audio_path\n",
    "\n",
    "def analyze_audio(audio_path):\n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = librosa.load(audio_path, sr=16000)\n",
    "    waveform = np.array(waveform, dtype=np.float32)\n",
    "\n",
    "    # Predict the audio event classes using YAMNet\n",
    "    scores, embeddings, spectrogram = yamnet(waveform)\n",
    "\n",
    "    # Print significant audio events detected\n",
    "    threshold = 0.1\n",
    "    significant_events = []\n",
    "    for i, score in enumerate(np.mean(scores, axis=0)):\n",
    "        if score > threshold:\n",
    "            significant_events.append(f\"Class: {class_names[i]}, Score: {score}\")\n",
    "    return significant_events\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"FINAL_IMSyPP_EN_644_PREPROCESSED_no_restricted_videos_features_2ktoken_w_prompt_u_desc.xlsx\")\n",
    "#df = df[:1]\n",
    "# Dictionary to store results of already analyzed audio files\n",
    "analyzed_audio = {}\n",
    "\n",
    "video_directory = \"NEW_Hatebase_dataset_downloaded_videos\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    video_path = os.path.join(video_directory, f\"{video_id}.mp4\")\n",
    "    if os.path.exists(video_path) and video_id not in analyzed_audio:\n",
    "        audio_path = extract_audio_from_video(video_path)\n",
    "        analyzed_audio[video_id] = analyze_audio(audio_path)\n",
    "        os.remove(audio_path)  # Clean up the extracted audio file\n",
    "    df.at[index, 'audio_events'] = analyzed_audio.get(video_id, [])\n",
    "\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "#df.to_excel(\"FINAL_IMSyPP_EN_644_PREPROCESSED_no_restricted_videos_features_2ktoken_w_prompt_u_desc_audio.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
